{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação das dependências necessárias\n",
    "!pip install \"tensorflow[and-cuda]\" tensorflow-hub\n",
    "!pip install -q tensorflow tensorflow_hub\n",
    "!pip install -q scikit-learn pandas numpy tqdm\n",
    "\n",
    "# Para usar o BGE-M3\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação da instalação do TensorFlow com suporte a GPU\n",
    "import tensorflow as tf, pprint\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "pprint.pprint(tf.sysconfig.get_build_info())  # mostra cuda_version e cudnn_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c204a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 23:28:02.698616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ricardo/Mestrado/TAIA/NLP-Embedding/.venv/lib/python3.10/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/home/ricardo/Mestrado/TAIA/NLP-Embedding/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Para usar o BGE-M3\n",
    "from sentence_transformers import SentenceTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9e10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12629, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando os dados\n",
    "df = pd.read_csv('eventos_artigos_filtrados.csv');\n",
    "df.shape\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7f2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados\n",
    "df = df.drop(columns=['evento_nome', 'resumo'])\n",
    "df = df.dropna(subset=['titulo_artigo', 'ano_edicao'])\n",
    "df['antes_2023'] = df['ano_edicao'].apply(lambda x: 1 if x < 2023 else 0)\n",
    "\n",
    "df[\"titulo_artigo\"] = df[\"titulo_artigo\"].astype(str).str.strip()\n",
    "df[\"antes_2023\"] = df[\"antes_2023\"].astype(int).values\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluir aqui outros tratamentos, SFC, normalização, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688e244",
   "metadata": {},
   "source": [
    "# Teste com BGE-M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913837a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGE-M3 carregado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 395/395 [00:40<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings gerados com sucesso! Shape final: (12629, 1024)\n"
     ]
    }
   ],
   "source": [
    "titulos = df['titulo_artigo'].tolist()\n",
    "labels = df['antes_2023'].values\n",
    "\n",
    "# Carregamento do Modelo BGE-M3 ---\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "print(\"BGE-M3 carregado com sucesso.\")\n",
    "\n",
    "# Execução da Geração de Embeddings ---\n",
    "embeddings_gerados = model.encode(\n",
    "    titulos,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEmbeddings gerados com sucesso! Shape final: {embeddings_gerados.shape}\")\n",
    "\n",
    "# --- Salvamento dos Resultados ---\n",
    "np.save('embeddings_titulos.npy', embeddings_gerados)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a8448",
   "metadata": {},
   "source": [
    "# CLASSIFICADOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4790f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados. Shape de X: (12629, 1024), Shape de y: (12629,)\n",
      "Dados divididos: 10103 para treino, 2526 para teste.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/Mestrado/TAIA/NLP-Embedding/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757042661.655359  227939 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7485 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,329</span> (513.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,329\u001b[0m (513.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,329</span> (513.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,329\u001b[0m (513.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o treinamento do classificador...\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 23:24:22.610427: I external/local_xla/xla/service/service.cc:163] XLA service 0x7ff82c0069b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-04 23:24:22.610440: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-09-04 23:24:22.623237: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-04 23:24:22.700306: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 158/2526\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.7643 - loss: 0.5852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757042663.302290  231400 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5459 - val_accuracy: 0.7328 - val_loss: 0.5294\n",
      "Epoch 2/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7356 - loss: 0.5179 - val_accuracy: 0.7379 - val_loss: 0.5249\n",
      "Epoch 3/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7420 - loss: 0.5060 - val_accuracy: 0.7399 - val_loss: 0.5190\n",
      "Epoch 4/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7495 - loss: 0.5006 - val_accuracy: 0.7411 - val_loss: 0.5221\n",
      "Epoch 5/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7602 - loss: 0.4882 - val_accuracy: 0.7439 - val_loss: 0.5251\n",
      "Epoch 6/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7629 - loss: 0.4803 - val_accuracy: 0.7502 - val_loss: 0.5185\n",
      "Epoch 7/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7725 - loss: 0.4697 - val_accuracy: 0.7387 - val_loss: 0.5177\n",
      "Epoch 8/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7792 - loss: 0.4538 - val_accuracy: 0.7514 - val_loss: 0.5267\n",
      "Epoch 9/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983us/step - accuracy: 0.7856 - loss: 0.4411 - val_accuracy: 0.7510 - val_loss: 0.5223\n",
      "Epoch 10/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4292 - val_accuracy: 0.7557 - val_loss: 0.5288\n",
      "Epoch 11/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8049 - loss: 0.4118 - val_accuracy: 0.7482 - val_loss: 0.5314\n",
      "Epoch 12/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 998us/step - accuracy: 0.8131 - loss: 0.3981 - val_accuracy: 0.7344 - val_loss: 0.5439\n",
      "Epoch 13/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977us/step - accuracy: 0.8244 - loss: 0.3815 - val_accuracy: 0.7534 - val_loss: 0.5499\n",
      "Epoch 14/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.3631 - val_accuracy: 0.7494 - val_loss: 0.5524\n",
      "Epoch 15/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3497 - val_accuracy: 0.7403 - val_loss: 0.5622\n",
      "Epoch 16/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - accuracy: 0.8505 - loss: 0.3378 - val_accuracy: 0.7482 - val_loss: 0.5681\n",
      "Epoch 17/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 987us/step - accuracy: 0.8571 - loss: 0.3207 - val_accuracy: 0.7451 - val_loss: 0.5933\n",
      "Epoch 18/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8674 - loss: 0.3037 - val_accuracy: 0.7264 - val_loss: 0.5903\n",
      "Epoch 19/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8741 - loss: 0.2887 - val_accuracy: 0.7490 - val_loss: 0.6303\n",
      "Epoch 20/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.2812 - val_accuracy: 0.7316 - val_loss: 0.6111\n",
      "Epoch 21/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8850 - loss: 0.2672 - val_accuracy: 0.7344 - val_loss: 0.6315\n",
      "Epoch 22/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.2499 - val_accuracy: 0.7316 - val_loss: 0.6391\n",
      "Epoch 23/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8958 - loss: 0.2477 - val_accuracy: 0.7312 - val_loss: 0.6535\n",
      "Epoch 24/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2284 - val_accuracy: 0.7344 - val_loss: 0.6841\n",
      "Epoch 25/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2225 - val_accuracy: 0.7348 - val_loss: 0.6921\n",
      "Epoch 26/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2190 - val_accuracy: 0.7328 - val_loss: 0.6908\n",
      "Epoch 27/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2090 - val_accuracy: 0.7324 - val_loss: 0.7139\n",
      "Epoch 28/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.1952 - val_accuracy: 0.7280 - val_loss: 0.7292\n",
      "Epoch 29/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.1894 - val_accuracy: 0.7233 - val_loss: 0.7470\n",
      "Epoch 30/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.1887 - val_accuracy: 0.7383 - val_loss: 0.7509\n",
      "Epoch 31/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.1793 - val_accuracy: 0.7249 - val_loss: 0.7621\n",
      "Epoch 32/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.1743 - val_accuracy: 0.7304 - val_loss: 0.7816\n",
      "Epoch 33/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.1683 - val_accuracy: 0.7332 - val_loss: 0.8364\n",
      "Epoch 34/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9344 - loss: 0.1647 - val_accuracy: 0.7359 - val_loss: 0.7922\n",
      "Epoch 35/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9369 - loss: 0.1559 - val_accuracy: 0.7348 - val_loss: 0.8538\n",
      "Epoch 36/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.1508 - val_accuracy: 0.7272 - val_loss: 0.8456\n",
      "Epoch 37/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step - accuracy: 0.9394 - loss: 0.1495 - val_accuracy: 0.7383 - val_loss: 0.8671\n",
      "Epoch 38/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.1456 - val_accuracy: 0.7383 - val_loss: 0.9027\n",
      "Epoch 39/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1390 - val_accuracy: 0.7280 - val_loss: 0.8889\n",
      "Epoch 40/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1373 - val_accuracy: 0.7328 - val_loss: 0.9112\n",
      "Epoch 41/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1293 - val_accuracy: 0.7407 - val_loss: 1.0131\n",
      "Epoch 42/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1294 - val_accuracy: 0.7276 - val_loss: 1.0043\n",
      "Epoch 43/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 999us/step - accuracy: 0.9520 - loss: 0.1246 - val_accuracy: 0.7379 - val_loss: 1.0339\n",
      "Epoch 44/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1297 - val_accuracy: 0.7288 - val_loss: 0.9389\n",
      "Epoch 45/45\n",
      "\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1214 - val_accuracy: 0.7328 - val_loss: 0.9941\n",
      "\n",
      "Avaliação final no conjunto de teste:\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7328 - loss: 0.9941\n",
      "Acurácia final no teste: 0.7328\n"
     ]
    }
   ],
   "source": [
    "# Carregamento dos Dados Pré-processados\n",
    "# Usou 10Gb VRAM\n",
    "\n",
    "X = np.load('embeddings_titulos.npy')\n",
    "y = np.load('labels.npy')\n",
    "\n",
    "print(f\"Dados carregados. Shape de X: {X.shape}, Shape de y: {y.shape}\")\n",
    "\n",
    "# --- Divisão em Treino e Teste ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\\n\")\n",
    "\n",
    "\n",
    "# --- Construção do Modelo de Classificação ---\n",
    "model = tf.keras.Sequential([\n",
    "    # A camada de entrada espera vetores com 1024 dimensões (o tamanho do embedding ELMo)\n",
    "    tf.keras.layers.InputLayer(input_shape=(1024,)),\n",
    "    \n",
    "    # Camada oculta para aprender padrões nos embeddings\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5), # Dropout para evitar overfitting\n",
    "    \n",
    "    # Camada de saída para classificação binária\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# --- Compilação do Modelo ---\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- Treinamento do Modelo ---\n",
    "print(\"\\nIniciando o treinamento do classificador...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=45,\n",
    "    batch_size=4,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Avaliação Final ---\n",
    "print(\"\\nAvaliação final no conjunto de teste:\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Acurácia final no teste: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2226ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('meu_classificador_com_BGE-M3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a84a93",
   "metadata": {},
   "source": [
    "# TESTE COM DADOS DIFERENTES DO DATASET A PARIR DE UM MODELO GERADO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0fcebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757042896.126251  237860 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7631 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2025-09-04 23:28:16.964021: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f401c003bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-04 23:28:16.964033: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-09-04 23:28:16.968619: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-04 23:28:16.980958: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "Título: 'Um estudo sobre o impacto da IA generativa no desenvolvimento de software'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 96.48%)\n",
      "\n",
      "Título: 'Implementação de algoritmos de parsing para compiladores em Pascal'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 99.71%)\n",
      "\n",
      "Título: 'Otimização de redes neurais para sistemas embarcados de baixa potência'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 98.81%)\n",
      "\n",
      "Título: 'Análise de sistemas de informação com metodologia estruturada'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 100.00%)\n",
      "\n",
      "Título: 'Fine-tuning de LLMs para tarefas de tradução em português'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 92.34%)\n",
      "\n",
      "Título: 'Knowledge graphs para recomendação de produtos em e-commerce'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 80.73%)\n",
      "\n",
      "Título: 'Análise de sentimentos em redes sociais utilizando BERT'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 100.00%)\n",
      "\n",
      "Título: 'Desenvolvimento de chatbots inteligentes com GPT-3'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 59.83%)\n",
      "\n",
      "Título: 'Avaliação de técnicas de segurança em redes de computadores'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 100.00%)\n",
      "\n",
      "Título: 'Estudo sobre algoritmos de compressão de dados para grandes volumes'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 95.12%)\n",
      "\n",
      "Título: 'Aplicações de aprendizado por reforço em jogos digitais'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 94.76%)\n",
      "\n",
      "Título: 'Técnicas de visualização de dados para análise exploratória'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 56.43%)\n",
      "\n",
      "Título: 'Desenvolvimento de sistemas distribuídos com microserviços'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 98.13%)\n",
      "\n",
      "Título: 'Análise de desempenho de bancos de dados NoSQL em aplicações web'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 99.99%)\n",
      "\n",
      "Título: 'Estudo sobre algoritmos de criptografia para segurança de dados'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 93.32%)\n",
      "\n",
      "Título: 'Implementação de redes neurais convolucionais para reconhecimento de imagens'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 99.66%)\n",
      "\n",
      "Título: 'Desenvolvimento de aplicações móveis com Flutter'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 99.87%)\n",
      "\n",
      "Título: 'Técnicas de mineração de dados para detecção de fraudes financeiras'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 72.78%)\n",
      "\n",
      "Título: 'Estudo sobre a evolução dos sistemas operacionais ao longo das décadas'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 75.24%)\n",
      "\n",
      "Título: 'Fine-tuning de LLMs para tarefas de tradução em português'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 92.34%)\n",
      "\n",
      "Título: 'knowledge distillation em modelos de linguagem grande'\n",
      "  -> Classificação: ANTES de 2023 (Confiança: 97.93%)\n",
      "\n",
      "Título: 'Compact models for edge AI applications'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 86.70%)\n",
      "\n",
      "Título: 'Analysis of Criminal Patterns in Police Report Narratives using Spectral Clustering with K-means'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 99.65%)\n",
      "\n",
      "Título: 'Knowledge Distillation in Compact Models: An Approach Applied to Text Processing for Public Security'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 69.11%)\n",
      "\n",
      "Título: 'Inteligência Artificial e sociedade: avanços e riscos'\n",
      "  -> Classificação: 2023 ou DEPOIS (Confiança: 56.94%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757042897.306642  238200 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar o Modelo de Embedding (BGE-M3)\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "# 2. Carregar o seu Classificador Keras treinado\n",
    "classificador = tf.keras.models.load_model('meu_classificador_com_BGE-M3.keras')\n",
    "\n",
    "novos_titulos = [\n",
    "    \"Um estudo sobre o impacto da IA generativa no desenvolvimento de software\",\n",
    "    \"Implementação de algoritmos de parsing para compiladores em Pascal\",\n",
    "    \"Otimização de redes neurais para sistemas embarcados de baixa potência\",\n",
    "    \"Análise de sistemas de informação com metodologia estruturada\",\n",
    "    \"Fine-tuning de LLMs para tarefas de tradução em português\",\n",
    "    \"Knowledge graphs para recomendação de produtos em e-commerce\",\n",
    "    \"Análise de sentimentos em redes sociais utilizando BERT\",\n",
    "    \"Desenvolvimento de chatbots inteligentes com GPT-3\",\n",
    "    \"Avaliação de técnicas de segurança em redes de computadores\",\n",
    "    \"Estudo sobre algoritmos de compressão de dados para grandes volumes\",\n",
    "    \"Aplicações de aprendizado por reforço em jogos digitais\",\n",
    "    \"Técnicas de visualização de dados para análise exploratória\",\n",
    "    \"Desenvolvimento de sistemas distribuídos com microserviços\",\n",
    "    \"Análise de desempenho de bancos de dados NoSQL em aplicações web\",\n",
    "    \"Estudo sobre algoritmos de criptografia para segurança de dados\",\n",
    "    \"Implementação de redes neurais convolucionais para reconhecimento de imagens\",\n",
    "    \"Desenvolvimento de aplicações móveis com Flutter\",\n",
    "    \"Técnicas de mineração de dados para detecção de fraudes financeiras\",\n",
    "    \"Estudo sobre a evolução dos sistemas operacionais ao longo das décadas\",\n",
    "    \"Fine-tuning de LLMs para tarefas de tradução em português\",\n",
    "    \"knowledge distillation em modelos de linguagem grande\",\n",
    "    \"Compact models for edge AI applications\",\n",
    "    \"Analysis of Criminal Patterns in Police Report Narratives using Spectral Clustering with K-means\",\n",
    "    \"Knowledge Distillation in Compact Models: An Approach Applied to Text Processing for Public Security\",\n",
    "    \"Inteligência Artificial e sociedade: avanços e riscos\"\n",
    "]\n",
    "\n",
    "novos_embeddings = embedding_model.encode(novos_titulos)\n",
    "predicoes_prob = classificador.predict(novos_embeddings)\n",
    "\n",
    "# Resultados\n",
    "for i, titulo in enumerate(novos_titulos):\n",
    "    prob = predicoes_prob[i][0]\n",
    "    \n",
    "    if prob > 0.5:\n",
    "        # Classe 1\n",
    "        classificacao = \"ANTES de 2023\"\n",
    "        confianca = prob * 100\n",
    "    else:\n",
    "        # Classe 0\n",
    "        classificacao = \"2023 ou DEPOIS\"\n",
    "        confianca = (1 - prob) * 100\n",
    "        \n",
    "    print(f\"Título: '{titulo}'\")\n",
    "    print(f\"  -> Classificação: {classificacao} (Confiança: {confianca:.2f}%)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
